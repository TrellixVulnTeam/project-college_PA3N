{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from flurs.datasets import fetch_movielens\n",
    "from flurs.recommender import FMRecommender\n",
    "from flurs.evaluator import Evaluator\n",
    "from flurs.data.entity import User, Item, Event\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "from calendar import monthrange\n",
    "from datetime import datetime, timedelta\n",
    "import csv\n",
    "\n",
    "from sklearn.utils import Bunch\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object Evaluator.evaluate at 0x7f63e31ccc78>\n"
     ]
    }
   ],
   "source": [
    "# converting data into FluRS input object\n",
    "data = fetch_movielens(data_home='data/ml-1m', size='1m')\n",
    "\n",
    "# logging.info('initialize recommendation model and evaluation module')\n",
    "rec = FMRecommender(p=sum(data.contexts.values()),  # number of dimensions of input vector\n",
    "                    k=40,\n",
    "                    l2_reg_w0=2.,\n",
    "                    l2_reg_w=8.,\n",
    "                    l2_reg_V=16.,\n",
    "                    learn_rate=.004)\n",
    "rec.initialize()\n",
    "evaluator = Evaluator(rec, data.can_repeat)\n",
    "\n",
    "n_batch_train = int(data.n_sample * 0.2)  # 20% for pre-training to avoid cold-start\n",
    "n_batch_test = int(data.n_sample * 0.1)  # 10% for evaluation of pre-training\n",
    "batch_tail = n_batch_train + n_batch_test\n",
    "\n",
    "# pre-train\n",
    "# 20% for batch training | 10% for batch evaluate\n",
    "# after the batch training, 10% samples are used for incremental updating\n",
    "# logging.info('batch pre-training before streaming input')\n",
    "evaluator.fit(\n",
    "    data.samples[:n_batch_train],\n",
    "    data.samples[n_batch_train:batch_tail],\n",
    "    n_epoch=1  # single pass even for batch training\n",
    ")\n",
    "\n",
    "# 70% incremental evaluation and updating\n",
    "# logging.info('incrementally predict, evaluate and update the recommender')\n",
    "res = evaluator.evaluate(data.samples[batch_tail:])\n",
    "\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_users = len(rec.users.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_movies(data_home, size):\n",
    "    \"\"\"Load movie genres as a context.\n",
    "    Returns:\n",
    "        dict of movie vectors: item_id -> numpy array (n_genre,)\n",
    "    \"\"\"\n",
    "    all_genres = ['Action',\n",
    "                  'Adventure',\n",
    "                  'Animation',\n",
    "                  \"Children\",\n",
    "                  'Comedy',\n",
    "                  'Crime',\n",
    "                  'Documentary',\n",
    "                  'Drama',\n",
    "                  'Fantasy',\n",
    "                  'Film-Noir',\n",
    "                  'Horror',\n",
    "                  'Musical',\n",
    "                  'Mystery',\n",
    "                  'Romance',\n",
    "                  'Sci-Fi',\n",
    "                  'Thriller',\n",
    "                  'War',\n",
    "                  'Western',\n",
    "                 'IMAX',\n",
    "                 '(no genres listed)']\n",
    "    n_genre = len(all_genres)\n",
    "\n",
    "    movies = {}\n",
    "\n",
    "    if size == 'latest-small':\n",
    "        with open(os.path.join(data_home, 'movies.csv'), encoding='ISO-8859-1') as f:\n",
    "            csv_reader = csv.DictReader(f)\n",
    "            for row in csv_reader:\n",
    "                item_id_str = row['movieId']\n",
    "                title = row['title']\n",
    "                genres = row['genres']\n",
    "\n",
    "                movie_vec = np.zeros(n_genre)\n",
    "                for genre in genres.split('|'):\n",
    "                    i = all_genres.index(genre)\n",
    "                    movie_vec[i] = 1.\n",
    "                item_id = int(item_id_str)\n",
    "                movies[item_id] = movie_vec\n",
    "    else:\n",
    "        print('ERROR')\n",
    "\n",
    "    return movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 269 ms, sys: 24 ms, total: 293 ms\n",
      "Wall time: 290 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "_ = load_movies(data_home=DATA_DIR, size='latest-small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(DATA_DIR, 'ratings.csv'), encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rating'] = [int(x) for x in df['rating']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[         1,        307,          3, 1256677221],\n",
       "       [         1,        481,          3, 1256677456],\n",
       "       [         1,       1091,          1, 1256677471],\n",
       "       ...,\n",
       "       [    283228,      34405,          4, 1379882889],\n",
       "       [    283228,      44761,          4, 1354159524],\n",
       "       [    283228,      54286,          4, 1354159718]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ratings(data_home, size):\n",
    "    df = pd.read_csv(os.path.join(data_home, 'ratings.csv'), encoding='ISO-8859-1')\n",
    "    df['rating'] = [int(x) for x in df['rating']]\n",
    "    users = sorted(list(set(df['userId'])))\n",
    "    sorted_data = df.values[np.argsort(df.values[:, 3])]\n",
    "    return (users, sorted_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, data = load_ratings(DATA_DIR, size='latest-small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[     56769,       1176,          4,  789652004],\n",
       "       [    237556,       1079,          3,  789652009],\n",
       "       [    237556,         47,          5,  789652009],\n",
       "       ...,\n",
       "       [    280481,        494,          3, 1537945127],\n",
       "       [     82922,      53519,          4, 1537945130],\n",
       "       [     82922,     167780,          4, 1537945149]])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delta(d1, d2, opt='d'):\n",
    "    delta = 0\n",
    "\n",
    "    if opt == 'm':\n",
    "        while True:\n",
    "            mdays = monthrange(d1.year, d1.month)[1]\n",
    "            d1 += timedelta(days=mdays)\n",
    "            if d1 <= d2:\n",
    "                delta += 1\n",
    "            else:\n",
    "                break\n",
    "    else:\n",
    "        delta = (d2 - d1).days\n",
    "\n",
    "    return delta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_genres = ['Action',\n",
    "                  'Adventure',\n",
    "                  'Animation',\n",
    "                  \"Children\",\n",
    "                  'Comedy',\n",
    "                  'Crime',\n",
    "                  'Documentary',\n",
    "                  'Drama',\n",
    "                  'Fantasy',\n",
    "                  'Film-Noir',\n",
    "                  'Horror',\n",
    "                  'Musical',\n",
    "                  'Mystery',\n",
    "                  'Romance',\n",
    "                  'Sci-Fi',\n",
    "                  'Thriller',\n",
    "                  'War',\n",
    "                  'Western',\n",
    "                 'IMAX',\n",
    "                 '(no genres listed)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting ratings...\n",
      "Getting movies...\n"
     ]
    }
   ],
   "source": [
    "# print('Getting ratings...')\n",
    "# users, ratings = load_ratings(DATA_DIR, size='latest-small')\n",
    "# print('Getting movies...')\n",
    "# movies = load_movies(DATA_DIR, size='latest-small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_movielens(data_home=None, size='latest-small', metadata = {}):\n",
    "    assert data_home is not None\n",
    "\n",
    "    if size not in ('100k', '1m', 'latest-small'):\n",
    "        raise ValueError(\"size can only be '100k' or '1m', got %s\" % size)\n",
    "\n",
    "    print('Getting ratings...')\n",
    "    users, ratings = load_ratings(data_home, size)\n",
    "    print('Getting movies...')\n",
    "    movies = load_movies(data_home, size)\n",
    "\n",
    "    samples = []\n",
    "\n",
    "    user_ids = {}\n",
    "    item_ids = {}\n",
    "\n",
    "    head_date = datetime(*time.localtime(ratings[0, 3])[:6])\n",
    "    dts = []\n",
    "\n",
    "    last = {}\n",
    "\n",
    "    cnt = 0\n",
    "    print('Processing ratings...')\n",
    "    for user_id, item_id, rating, timestamp in tqdm(ratings):\n",
    "        # give an unique user index\n",
    "        if user_id in user_ids:\n",
    "            u_index = user_ids[user_id]\n",
    "        else:\n",
    "            u_index = len(user_ids)\n",
    "            user_ids[user_id] = u_index\n",
    "\n",
    "        # give an unique item index\n",
    "        if item_id in item_ids:\n",
    "            i_index = item_ids[item_id]\n",
    "        else:\n",
    "            i_index = len(item_ids)\n",
    "            item_ids[item_id] = i_index\n",
    "\n",
    "        # delta days\n",
    "        date = datetime(*time.localtime(timestamp)[:6])\n",
    "        dt = delta(head_date, date)\n",
    "        dts.append(dt)\n",
    "\n",
    "        weekday_vec = np.zeros(7)\n",
    "        weekday_vec[date.weekday()] = 1\n",
    "\n",
    "        if user_id in last:\n",
    "            last_item_vec = last[user_id]['item']\n",
    "#             last_weekday_vec = last[user_id]['weekday']\n",
    "        else:\n",
    "            last_item_vec = np.zeros(20)\n",
    "#             last_weekday_vec = np.zeros(7)\n",
    "\n",
    "        others = np.concatenate((weekday_vec, last_item_vec))\n",
    "#         print('others.shape: ', others.shape)\n",
    "\n",
    "        user = User(u_index, np.zeros(1))\n",
    "        item = Item(i_index, movies[item_id])\n",
    "\n",
    "        sample = Event(user, item, 1., others)\n",
    "        samples.append(sample)\n",
    "\n",
    "        # record users' last rated movie features\n",
    "        last[user_id] = {'item': movies[item_id] }\n",
    "        cnt += 1\n",
    "        if cnt > 20000:\n",
    "            break\n",
    "    metadata['userids'] = user_ids\n",
    "    metadata['itemids'] = item_ids\n",
    "    print('Done loading!')\n",
    "\n",
    "    # contexts in this dataset\n",
    "    # 1 delta time, 18 genres, and 23 demographics (1 for M/F, 1 for age, 21 for occupation(0-20))\n",
    "    # 7 for day of week, 18 for the last rated item genres, 7 for the last day of week\n",
    "    return Bunch(samples=samples,\n",
    "                 can_repeat=False,\n",
    "                 contexts={'others': 7 + 20, 'item': 20, 'user': 1},\n",
    "                 n_user=len(user_ids),\n",
    "                 n_item=len(item_ids),\n",
    "                 n_sample=len(samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/27753444 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|          | 8254/27753444 [00:00<05:36, 82534.77it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ratings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 16962/27753444 [00:00<05:30, 83844.34it/s]\u001b[A\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done loading!\n"
     ]
    }
   ],
   "source": [
    "data = fetch_movielens(data_home=DATA_DIR, size='latest-small')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = load_movies(DATA_DIR, size='latest-small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20,)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'others': 27, 'item': 20}"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['samples', 'can_repeat', 'contexts', 'n_user', 'n_item', 'n_sample'])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object Evaluator.evaluate at 0x7f61c8738228>\n"
     ]
    }
   ],
   "source": [
    "# converting data into FluRS input object\n",
    "# data = fetch_movielens(data_home=DATA_DIR, size='latest-small')\n",
    "\n",
    "# logging.info('initialize recommendation model and evaluation module')\n",
    "rec = FMRecommender(p=sum(data.contexts.values()),  # number of dimensions of input vector\n",
    "                    k=40,\n",
    "                    l2_reg_w0=2.,\n",
    "                    l2_reg_w=8.,\n",
    "                    l2_reg_V=16.,\n",
    "                    learn_rate=.004)\n",
    "rec.initialize()\n",
    "evaluator = Evaluator(rec, data.can_repeat)\n",
    "\n",
    "n_batch_train = int(data.n_sample * 0.2)  # 20% for pre-training to avoid cold-start\n",
    "n_batch_test = int(data.n_sample * 0.1)  # 10% for evaluation of pre-training\n",
    "batch_tail = n_batch_train + n_batch_test\n",
    "\n",
    "# pre-train\n",
    "# 20% for batch training | 10% for batch evaluate\n",
    "# after the batch training, 10% samples are used for incremental updating\n",
    "# logging.info('batch pre-training before streaming input')\n",
    "evaluator.fit(\n",
    "    data.samples[:n_batch_train],\n",
    "    data.samples[n_batch_train:batch_tail],\n",
    "    n_epoch=1  # single pass even for batch training\n",
    ")\n",
    "\n",
    "# 70% incremental evaluation and updating\n",
    "# logging.info('incrementally predict, evaluate and update the recommender')\n",
    "res = evaluator.evaluate(data.samples[batch_tail:])\n",
    "\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.29070307510022064, 379, 0.006395000000338769, 0.025908000000526954)\n"
     ]
    }
   ],
   "source": [
    "for r in res:\n",
    "    print(r)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 25.5 s, sys: 3.6 s, total: 29.1 s\n",
      "Wall time: 20.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "_, _ = load_ratings(DATA_DIR, size='latest-small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR= 'data/ml-latest'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = fetch_movielens(data_home=DATA_DIR, size='1m', metadata=metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(DATA_DIR, 'users.dat'), encoding='ISO-8859-1') as f:\n",
    "    lines = map(lambda l: l.rstrip().split('::'), f.readlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
